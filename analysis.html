<html>
<head>
<title>analysis.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #8c8c8c; font-style: italic;}
.s1 { color: #080808;}
.s2 { color: #0033b3;}
.s3 { color: #067d17;}
.s4 { color: #1750eb;}
.s5 { color: #0037a6;}
.ls0 { height: 1px; border-width: 0; color: #dfe1e5; background-color:#dfe1e5}
</style>
</head>
<body bgcolor="#ffffff">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#c0c0c0" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
analysis.ipynb</font>
</center></td></tr></table>
<pre><span class="s0">#%% md 
</span><span class="s1"># Cookie Cats A/B Test: Retention Analysis 
 
**Author:** Ante Mislav Vukojević 
&lt;br&gt; 
 
### 1. The Business Problem 
 
This is an analysis of an A/B test conducted on the mobile game Cookie Cats. The game uses 'gates' that force players to wait a certain time before progressing. The objective is to determine if moving the first gate from level 30 to level 40 has a significant impact on player retention. 
 
The core question: **Which gate placement drives better long-term player engagement?** We will analyze 1-day and 7-day retention as our key metrics. <hr class="ls0"></span><span class="s0">#%% md 
</span><span class="s1">### 2. Setup &amp; Data Exploration 
 
First step is always to load the data and get a feel for it. Need to check for missing values, data types, and the overall structure to make sure the foundation of the analysis is solid. <hr class="ls0"></span><span class="s0">#%% 
# Import necessary libraries</span>
<span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>

<span class="s0"># Load the dataset</span>
<span class="s1">df = pd.read_csv(</span><span class="s3">'cookie_cats.csv'</span><span class="s1">)</span>

<span class="s0"># Initial check</span>
<span class="s1">df.head()</span><hr class="ls0"><span class="s0">#%% 
# Check for missing values and data types</span>
<span class="s1">df.info()</span><hr class="ls0"><span class="s0">#%% md 
</span><span class="s1">**Initial Findings:** 
* The dataset contains 90,189 records. 
* There are no missing values, which is great. 
* `retention_1` and `retention_7` are boolean types, which is perfect for calculating rates. <hr class="ls0"></span><span class="s0">#%% md 
</span><span class="s1">### 3. Comparing Retention Rates 
 
Let's get the first look at the results. A simple `groupby` on the test versions will show the mean retention for each group. This gives us the raw performance numbers. <hr class="ls0"></span><span class="s0">#%% 
# Calculate mean retention for each version</span>
<span class="s1">retention_by_version = df.groupby(</span><span class="s3">'version'</span><span class="s1">)[[</span><span class="s3">'retention_1'</span><span class="s1">, </span><span class="s3">'retention_7'</span><span class="s1">]].mean()</span>
<span class="s1">retention_by_version</span><hr class="ls0"><span class="s0">#%% md 
</span><span class="s1">**Analysis of Means:** 
 
On the surface, the `gate_30` version appears to perform slightly better on both metrics. 
* **1-Day Retention:** `gate_30` is higher by ~0.6%. 
* **7-Day Retention:** `gate_30` is higher by ~0.8%. 
 
The difference in 1-day retention is likely negligible from a user experience standpoint, as most players wouldn't have reached level 30 within their first day. The more telling metric should be 7-day retention, as more users would have hit the gate by then. 
 
The key question is whether this small difference is a real effect or just random noise in the data. For that, we need to check for statistical significance. <hr class="ls0"></span><span class="s0">#%% md 
</span><span class="s1">### 4. Statistical Significance Testing 
 
To test for significance, I'll use bootstrapping. It's a robust and intuitive method that relies on computational simulation rather than traditional statistical assumptions. The process simulates running the experiment thousands of times to see how often our observed result occurs, which gives us a p-value. 
 
I'm using a vectorized NumPy implementation here because it's significantly faster than a standard Python `for` loop. <hr class="ls0"></span><span class="s0">#%% 
# Store the boolean retention data for each group in NumPy arrays for efficiency</span>
<span class="s1">retention_1_30 = df[df[</span><span class="s3">'version'</span><span class="s1">] == </span><span class="s3">'gate_30'</span><span class="s1">][</span><span class="s3">'retention_1'</span><span class="s1">].values</span>
<span class="s1">retention_1_40 = df[df[</span><span class="s3">'version'</span><span class="s1">] == </span><span class="s3">'gate_40'</span><span class="s1">][</span><span class="s3">'retention_1'</span><span class="s1">].values</span>
<span class="s1">retention_7_30 = df[df[</span><span class="s3">'version'</span><span class="s1">] == </span><span class="s3">'gate_30'</span><span class="s1">][</span><span class="s3">'retention_7'</span><span class="s1">].values</span>
<span class="s1">retention_7_40 = df[df[</span><span class="s3">'version'</span><span class="s1">] == </span><span class="s3">'gate_40'</span><span class="s1">][</span><span class="s3">'retention_7'</span><span class="s1">].values</span>

<span class="s0"># Set number of bootstrap iterations</span>
<span class="s1">iterations = </span><span class="s4">10000</span>

<span class="s0"># --- 1-Day Retention Simulation ---</span>
<span class="s1">boot_1d_30 = np.random.choice(retention_1_30, size=(iterations, len(retention_1_30)), replace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">boot_1d_40 = np.random.choice(retention_1_40, size=(iterations, len(retention_1_40)), replace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">boot_1d_diff = boot_1d_30.mean(axis=</span><span class="s4">1</span><span class="s1">) - boot_1d_40.mean(axis=</span><span class="s4">1</span><span class="s1">)</span>

<span class="s0"># --- 7-Day Retention Simulation ---</span>
<span class="s1">boot_7d_30 = np.random.choice(retention_7_30, size=(iterations, len(retention_7_30)), replace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">boot_7d_40 = np.random.choice(retention_7_40, size=(iterations, len(retention_7_40)), replace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">boot_7d_diff = boot_7d_30.mean(axis=</span><span class="s4">1</span><span class="s1">) - boot_7d_40.mean(axis=</span><span class="s4">1</span><span class="s1">)</span>

<span class="s0"># --- Calculate P-Values ---</span>
<span class="s0"># The p-value is the probability that the observed difference is zero or negative</span>
<span class="s1">p_value_1d = (boot_1d_diff &lt;= </span><span class="s4">0</span><span class="s1">).mean()</span>
<span class="s1">p_value_7d = (boot_7d_diff &lt;= </span><span class="s4">0</span><span class="s1">).mean()</span>

<span class="s1">print(</span><span class="s3">f&quot;P-value for 1-day retention: </span><span class="s5">{</span><span class="s1">p_value_1d</span><span class="s5">:</span><span class="s3">.4f</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s1">)</span>
<span class="s1">print(</span><span class="s3">f&quot;P-value for 7-day retention: </span><span class="s5">{</span><span class="s1">p_value_7d</span><span class="s5">:</span><span class="s3">.4f</span><span class="s5">}</span><span class="s3">&quot;</span><span class="s1">)</span><hr class="ls0"><span class="s0">#%% md 
</span><span class="s1">**Significance Analysis:** 
 
Using a standard significance level of α = 0.05: 
* **1-Day Retention:** The p-value is significant (p &lt; 0.05). 
* **7-Day Retention:** The p-value is highly statistically significant (p &lt; 0.01). 
 
This confirms that the drop in retention for the `gate_40` group is a real effect and not just due to random chance. The effect is much stronger for the more important 7-day metric. <hr class="ls0"></span><span class="s0">#%% md 
</span><span class="s1">### 5. Visualization 
 
A clustered bar chart is the best way to present these findings to stakeholders. It provides a clear, immediate visual comparison of the performance of the two groups across both metrics. <hr class="ls0"></span><span class="s0">#%% 
# --- Data Preparation for plotting ---</span>
<span class="s1">labels = [</span><span class="s3">'1-Day Retention'</span><span class="s1">, </span><span class="s3">'7-Day Retention'</span><span class="s1">]</span>
<span class="s1">gate_30_means = retention_by_version.loc[</span><span class="s3">'gate_30'</span><span class="s1">].values</span>
<span class="s1">gate_40_means = retention_by_version.loc[</span><span class="s3">'gate_40'</span><span class="s1">].values</span>

<span class="s1">x = np.arange(len(labels))  </span><span class="s0"># the label locations</span>
<span class="s1">width = </span><span class="s4">0.35  </span><span class="s0"># the width of the bars</span>

<span class="s0"># --- Chart Creation ---</span>
<span class="s1">plt.style.use(</span><span class="s3">'seaborn-v0_8-whitegrid'</span><span class="s1">)</span>
<span class="s1">fig, ax = plt.subplots(figsize=(</span><span class="s4">10</span><span class="s1">, </span><span class="s4">6</span><span class="s1">))</span>

<span class="s1">rects1 = ax.bar(x - width/</span><span class="s4">2</span><span class="s1">, gate_30_means, width, label=</span><span class="s3">'Gate at Level 30'</span><span class="s1">)</span>
<span class="s1">rects2 = ax.bar(x + width/</span><span class="s4">2</span><span class="s1">, gate_40_means, width, label=</span><span class="s3">'Gate at Level 40'</span><span class="s1">)</span>

<span class="s0"># --- Professional Touches ---</span>
<span class="s1">ax.set_title(</span><span class="s3">'1-Day and 7-Day Player Retention by AB-Test Group'</span><span class="s1">, fontsize=</span><span class="s4">16</span><span class="s1">)</span>
<span class="s1">ax.set_ylabel(</span><span class="s3">'Retention Rate'</span><span class="s1">, fontsize=</span><span class="s4">12</span><span class="s1">)</span>
<span class="s1">ax.set_xticks(x)</span>
<span class="s1">ax.set_xticklabels(labels, fontsize=</span><span class="s4">12</span><span class="s1">)</span>
<span class="s1">ax.legend()</span>

<span class="s1">ax.bar_label(rects1, padding=</span><span class="s4">3</span><span class="s1">, fmt=</span><span class="s3">'%.3f'</span><span class="s1">)</span>
<span class="s1">ax.bar_label(rects2, padding=</span><span class="s4">3</span><span class="s1">, fmt=</span><span class="s3">'%.3f'</span><span class="s1">)</span>

<span class="s1">fig.tight_layout()</span>

<span class="s0"># --- Save the chart to a file ---</span>
<span class="s1">plt.savefig(</span><span class="s3">'retention_chart.png'</span><span class="s1">, dpi=</span><span class="s4">300</span><span class="s1">)</span>

<span class="s1">plt.show()</span><hr class="ls0"><span class="s0">#%% md 
</span><span class="s1">### 6. Conclusion &amp; Recommendation 
 
The analysis is clear and the results are statistically significant. 
 
Both 1-day and 7-day retention rates are negatively impacted by moving the gate from level 30 to level 40. The effect on 7-day retention is particularly strong, which is a critical metric for predicting the long-term health of the player base. A lower 7-day retention rate will almost certainly lead to lower overall player lifetime value. 
 
**Recommendation:** The company should **not** roll out the change. The gate should be kept at level 30 to maximize long-term player engagement.</span></pre>
</body>
</html>